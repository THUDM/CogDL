{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cogdl.datasets.grb_data import Cora_GRBDataset\n",
    "from cogdl.utils import set_random_seed\n",
    "from cogdl.utils.grb_utils import evaluate, GCNAdjNorm\n",
    "import copy\n",
    "import torch\n",
    "dataset = Cora_GRBDataset()\n",
    "graph = copy.deepcopy(dataset.get(0))\n",
    "# device = \"cpu\"\n",
    "device = \"cuda:0\"\n",
    "device_ids = [0]\n",
    "graph.to(device)\n",
    "test_mask = graph.test_mask\n",
    "set_random_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GCNLayer(\n",
      "      (linear): Linear(in_features=302, out_features=64, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): GCNLayer(\n",
      "      (linear): Linear(in_features=64, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Model Parameters: 19847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200, train_loss:  0.5650, val_acc:  0.8060: 100%|██████████| 200/200 [00:03<00:00, 64.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 174-th model to ./checkpoints/model.pt ...\n",
      "Loading model from ./checkpoints/model.pt ...\n",
      "{'test_acc': 0.8171641791044776, 'val_acc': 0.8246268656716418}\n",
      "Test score before attack for surrogate model: 0.8172.\n"
     ]
    }
   ],
   "source": [
    "# train surrogate model\n",
    "from cogdl.models.nn import GCN\n",
    "from cogdl.trainer import Trainer\n",
    "from cogdl.wrappers import fetch_model_wrapper, fetch_data_wrapper\n",
    "model_sur = GCN(\n",
    "    in_feats=graph.num_features,\n",
    "    hidden_size=64,\n",
    "    out_feats=graph.num_classes,\n",
    "    num_layers=2,\n",
    "    dropout=0.5,\n",
    "    activation=\"relu\"\n",
    ")\n",
    "print(model_sur)\n",
    "mw_class = fetch_model_wrapper(\"node_classification_mw\")\n",
    "dw_class = fetch_data_wrapper(\"node_classification_dw\")\n",
    "optimizer_cfg = dict(\n",
    "                    lr=0.01,\n",
    "                    weight_decay=0\n",
    "                )\n",
    "model_wrapper = mw_class(model_sur, optimizer_cfg)\n",
    "dataset_wrapper = dw_class(dataset)\n",
    "trainer = Trainer(epochs=200,\n",
    "                  early_stopping=True,\n",
    "                  patience=50,\n",
    "                  cpu=device==\"cpu\",\n",
    "                  device_ids=device_ids)\n",
    "trainer.run(model_wrapper, dataset_wrapper)\n",
    "model_sur.load_state_dict(torch.load(\"./checkpoints/model.pt\"), False)\n",
    "model_sur.to(device)\n",
    "test_score = evaluate(model_sur,\n",
    "                      graph,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"Test score before attack for surrogate model: {:.4f}.\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 24263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 116, train_loss:  0.4251, val_acc:  0.7948:  58%|█████▊    | 116/200 [00:02<00:01, 42.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 67-th model to ./checkpoints/model.pt ...\n",
      "Loading model from ./checkpoints/model.pt ...\n",
      "{'test_acc': 0.8196517412935324, 'val_acc': 0.8097014925373134}\n",
      "Test score before attack for target model: 0.8197.\n"
     ]
    }
   ],
   "source": [
    "# train target model\n",
    "\n",
    "model_target = GCN(\n",
    "    in_feats=graph.num_features,\n",
    "    hidden_size=64,\n",
    "    out_feats=graph.num_classes,\n",
    "    num_layers=3,\n",
    "    dropout=0.5,\n",
    "    activation=None,\n",
    "    norm=\"layernorm\"\n",
    ")\n",
    "mw_class = fetch_model_wrapper(\"node_classification_mw\")\n",
    "dw_class = fetch_data_wrapper(\"node_classification_dw\")\n",
    "optimizer_cfg = dict(\n",
    "                    lr=0.01,\n",
    "                    weight_decay=0\n",
    "                )\n",
    "model_wrapper = mw_class(model_target, optimizer_cfg)\n",
    "dataset_wrapper = dw_class(dataset)\n",
    "trainer = Trainer(epochs=200,\n",
    "                  early_stopping=True,\n",
    "                  patience=50,\n",
    "                  cpu=device==\"cpu\",\n",
    "                  device_ids=device_ids)\n",
    "trainer.run(model_wrapper, dataset_wrapper)\n",
    "model_target.load_state_dict(torch.load(\"./checkpoints/model.pt\"), False)\n",
    "model_target.to(device)\n",
    "test_score = evaluate(model_target,\n",
    "                      graph,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"Test score before attack for target model: {:.4f}.\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 79239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 681, train_loss:  1.4261, val_acc:  0.7575:  34%|███▍      | 681/2000 [00:24<00:46, 28.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 182-th model to ./checkpoints/model.pt ...\n",
      "Loading model from ./checkpoints/model.pt ...\n",
      "{'test_acc': 0.7985074626865671, 'val_acc': 0.832089552238806}\n",
      "Test score before attack for target model: 0.6604.\n"
     ]
    }
   ],
   "source": [
    "# train target model\n",
    "\n",
    "from cogdl.models.nn import SAGE\n",
    "\n",
    "model_target = SAGE(\n",
    "    graph.num_features,\n",
    "    graph.num_classes,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.5,\n",
    "    norm=None\n",
    ")\n",
    "print(model_target)\n",
    "mw_class = fetch_model_wrapper(\"node_classification_mw\")\n",
    "dw_class = fetch_data_wrapper(\"node_classification_dw\")\n",
    "optimizer_cfg = dict(\n",
    "                    lr=0.01,\n",
    "                    weight_decay=0\n",
    "                )\n",
    "model_wrapper = mw_class(model_target, optimizer_cfg)\n",
    "dataset_wrapper = dw_class(dataset)\n",
    "trainer = Trainer(epochs=200,\n",
    "                  early_stopping=True,\n",
    "                  patience=50,\n",
    "                  cpu=device==\"cpu\",\n",
    "                  device_ids=device_ids)\n",
    "trainer.run(model_wrapper, dataset_wrapper)\n",
    "model_target.load_state_dict(torch.load(\"./checkpoints/model.pt\"), False)\n",
    "model_target.to(device)\n",
    "test_score_target_raw = evaluate(model_target,\n",
    "                                 graph,\n",
    "                                 mask=test_mask,\n",
    "                                 device=device)\n",
    "print(\"Test score before attack for target model: {:.4f}.\".format(test_score_target_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/xu-ll18/research/cogdl/injection_attack.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcogdl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mattack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minjection\u001b[39;00m \u001b[39mimport\u001b[39;00m FGSM\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=2'>3</a>\u001b[0m attack \u001b[39m=\u001b[39m FGSM(epsilon\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=3'>4</a>\u001b[0m               n_epoch\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=4'>5</a>\u001b[0m               n_inject_max\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=7'>8</a>\u001b[0m               feat_lim_max\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=8'>9</a>\u001b[0m               device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=9'>10</a>\u001b[0m graph_attack \u001b[39m=\u001b[39m attack\u001b[39m.\u001b[39;49mattack(model\u001b[39m=\u001b[39;49mmodel_sur,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=10'>11</a>\u001b[0m                              graph\u001b[39m=\u001b[39;49mgraph,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=11'>12</a>\u001b[0m                              adj_norm_func\u001b[39m=\u001b[39;49mGCNAdjNorm)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=12'>13</a>\u001b[0m graph_attack\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39my\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/injection_attack.ipynb#ch0000005vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(graph_attack)\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/attack/injection/fgsm.py:128\u001b[0m, in \u001b[0;36mFGSM.attack\u001b[0;34m(self, model, graph, feat_norm, adj_norm_func)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=121'>122</a>\u001b[0m features \u001b[39m=\u001b[39m feat_preprocess(features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=122'>123</a>\u001b[0m                            feat_norm\u001b[39m=\u001b[39mfeat_norm,\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=123'>124</a>\u001b[0m                            device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=124'>125</a>\u001b[0m adj_tensor \u001b[39m=\u001b[39m adj_preprocess(adj\u001b[39m=\u001b[39madj,\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=125'>126</a>\u001b[0m                             adj_norm_func\u001b[39m=\u001b[39madj_norm_func,\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=126'>127</a>\u001b[0m                             device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=127'>128</a>\u001b[0m pred_origin \u001b[39m=\u001b[39m model(getGraph(adj_tensor, features))\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=128'>129</a>\u001b[0m labels_origin \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(pred_origin, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=129'>130</a>\u001b[0m adj_attack \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minjection(adj\u001b[39m=\u001b[39madj,\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=130'>131</a>\u001b[0m                             n_inject\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inject_max,\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=131'>132</a>\u001b[0m                             n_node\u001b[39m=\u001b[39mn_total,\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/injection/fgsm.py?line=132'>133</a>\u001b[0m                             target_mask\u001b[39m=\u001b[39mtarget_mask)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/models/nn/gcn.py:84\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=81'>82</a>\u001b[0m h \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mx\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=82'>83</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=83'>84</a>\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i](graph, h)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=84'>85</a>\u001b[0m \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/layers/gcn_layer.py:53\u001b[0m, in \u001b[0;36mGCNLayer.forward\u001b[0;34m(self, graph, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, graph, x):\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=51'>52</a>\u001b[0m     support \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(x)\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=52'>53</a>\u001b[0m     out \u001b[39m=\u001b[39m spmm(graph, support)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=54'>55</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=55'>56</a>\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(out)\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/utils/spmm_utils.py:122\u001b[0m, in \u001b[0;36mspmm\u001b[0;34m(graph, x, actnn, fast_spmm, fast_spmm_cpu)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=119'>120</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=120'>121</a>\u001b[0m     row, col \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39medge_index\n\u001b[0;32m--> <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=121'>122</a>\u001b[0m     x \u001b[39m=\u001b[39m spmm_scatter(row, col, graph\u001b[39m.\u001b[39;49medge_weight, x)\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=122'>123</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/utils/spmm_utils.py:50\u001b[0m, in \u001b[0;36mspmm_scatter\u001b[0;34m(row, col, values, b)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=42'>43</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspmm_scatter\u001b[39m(row, col, values, b):\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=43'>44</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=44'>45</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=45'>46</a>\u001b[0m \u001b[39m        (row, col): Tensor, shape=(2, E)\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=46'>47</a>\u001b[0m \u001b[39m        values : Tensor, shape=(E,)\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=47'>48</a>\u001b[0m \u001b[39m        b : Tensor, shape=(N, d)\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=48'>49</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=49'>50</a>\u001b[0m     output \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39;49mindex_select(\u001b[39m0\u001b[39;49m, col) \u001b[39m*\u001b[39m values\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(b\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=50'>51</a>\u001b[0m     output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(b)\u001b[39m.\u001b[39mscatter_add_(\u001b[39m0\u001b[39m, row\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand_as(output), output)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/utils/spmm_utils.py?line=51'>52</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# FGSM attack\n",
    "from cogdl.attack.injection import FGSM\n",
    "attack = FGSM(epsilon=0.01,\n",
    "              n_epoch=1000,\n",
    "              n_inject_max=100,\n",
    "              n_edge_max=200,\n",
    "              feat_lim_min=-1,\n",
    "              feat_lim_max=1,\n",
    "              device=device)\n",
    "graph_attack = attack.attack(model=model_sur,\n",
    "                             graph=graph,\n",
    "                             adj_norm_func=GCNAdjNorm)\n",
    "\n",
    "# apply injection attack\n",
    "test_score_sur = evaluate(model_sur,\n",
    "                          graph_attack,\n",
    "                          mask=test_mask,\n",
    "                          device=device)\n",
    "print(\"Test score after attack for surrogate model: {:.4f}.\".format(test_score_sur))\n",
    "\n",
    "# transfer to target model\n",
    "test_score_target_attack = evaluate(model_target,\n",
    "                                    graph_attack,\n",
    "                                    mask=test_mask,\n",
    "                                    device=device)\n",
    "print(\"Test score after attack for target model: {:.4f}.\".format(test_score_target_attack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999, Loss: 2.2342, Surrogate test score: 0.0771: 100%|██████████| 1000/1000 [00:35<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate test score: 0.0771\n",
      "Attack runtime: 35.4433.\n",
      "Graph(x=[2680, 302], y=[2680], train_mask=[2680], val_mask=[2680], test_mask=[2680], edge_index=[2, 10296], edge_weight=[10296], edge_attr=[10296])\n",
      "Graph(x=[2780, 302], y=[2680], edge_index=[2, 50296], edge_attr=[50296])\n",
      "Graph(x=[2780, 302], y=[2680], edge_index=[2, 50296], edge_weight=[50296], edge_attr=[50296])\n",
      "Test score after attack for surrogate model: 0.2786.\n",
      "Test score after attack for target model: 0.1816.\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.injection import PGD\n",
    "attack = PGD(epsilon=0.01,\n",
    "              n_epoch=1000,\n",
    "              n_inject_max=100,\n",
    "              n_edge_max=200,\n",
    "              feat_lim_min=-1,\n",
    "              feat_lim_max=1,\n",
    "              device=device)\n",
    "graph_attack = attack.attack(model=model_sur,\n",
    "                             graph=graph,\n",
    "                             adj_norm_func=GCNAdjNorm)\n",
    "\n",
    "# apply injection attack\n",
    "test_score_sur = evaluate(model_sur,\n",
    "                          graph_attack,\n",
    "                          mask=test_mask,\n",
    "                          device=device)\n",
    "print(\"Test score after attack for surrogate model: {:.4f}.\".format(test_score_sur))\n",
    "\n",
    "# transfer to target model\n",
    "test_score_target_attack = evaluate(model_target,\n",
    "                                    graph_attack,\n",
    "                                    mask=test_mask,\n",
    "                                    device=device)\n",
    "print(\"Test score after attack for target model: {:.4f}.\".format(test_score_target_attack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -1.8378, Surrogate test acc: 0.6965\n",
      "Attack runtime: 0.1471.\n",
      "Test score after attack for surrogate model: 0.3818.\n",
      "Test score after attack for target model: 0.3122.\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.injection import RAND\n",
    "attack = RAND(n_inject_max=100,\n",
    "              n_edge_max=200,\n",
    "              feat_lim_min=-1,\n",
    "              feat_lim_max=1,\n",
    "              device=device)\n",
    "graph_attack = attack.attack(model=model_sur,\n",
    "                             graph=graph,\n",
    "                             adj_norm_func=GCNAdjNorm)\n",
    "\n",
    "# apply injection attack\n",
    "test_score_sur = evaluate(model_sur,\n",
    "                          graph_attack,\n",
    "                          mask=test_mask,\n",
    "                          device=device)\n",
    "print(\"Test score after attack for surrogate model: {:.4f}.\".format(test_score_sur))\n",
    "\n",
    "# transfer to target model\n",
    "test_score_target_attack = evaluate(model_target,\n",
    "                                    graph_attack,\n",
    "                                    mask=test_mask,\n",
    "                                    device=device)\n",
    "print(\"Test score after attack for target model: {:.4f}.\".format(test_score_target_attack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999, Loss: -2.2334, Surrogate test score: 0.0771: 100%|██████████| 1000/1000 [00:33<00:00, 29.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate test score: 0.0771\n",
      "Attack runtime: 33.6856.\n",
      "Test score after attack for surrogate model: 0.2711.\n",
      "Test score after attack for target model: 0.2413.\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.injection import SPEIT\n",
    "attack = SPEIT(lr=0.02,\n",
    "               n_epoch=1000,\n",
    "               n_inject_max=100,\n",
    "               n_edge_max=200,\n",
    "               feat_lim_min=-1,\n",
    "               feat_lim_max=1,\n",
    "               device=device)\n",
    "graph_attack = attack.attack(model=model_sur,\n",
    "                             graph=graph,\n",
    "                             adj_norm_func=GCNAdjNorm)\n",
    "\n",
    "# apply injection attack\n",
    "test_score_sur = evaluate(model_sur,\n",
    "                          graph_attack,\n",
    "                          mask=test_mask,\n",
    "                          device=device)\n",
    "print(\"Test score after attack for surrogate model: {:.4f}.\".format(test_score_sur))\n",
    "\n",
    "# transfer to target model\n",
    "test_score_target_attack = evaluate(model_target,\n",
    "                                    graph_attack,\n",
    "                                    mask=test_mask,\n",
    "                                    device=device)\n",
    "print(\"Test score after attack for target model: {:.4f}.\".format(test_score_target_attack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 20/100 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999, Loss: 6.8068, Surrogate test score: 0.7363: 100%|██████████| 1000/1000 [00:17<00:00, 56.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 40/100 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999, Loss: 6.3547, Surrogate test score: 0.6978: 100%|██████████| 1000/1000 [00:18<00:00, 53.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 60/100 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999, Loss: 6.1741, Surrogate test score: 0.6903: 100%|██████████| 1000/1000 [00:21<00:00, 46.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 80/100 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999, Loss: 5.9993, Surrogate test score: 0.6816: 100%|██████████| 1000/1000 [00:22<00:00, 44.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking: Sequential inject 100/100 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999, Loss: 5.8305, Surrogate test score: 0.6729: 100%|██████████| 1000/1000 [00:23<00:00, 43.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack runtime: 104.0285.\n",
      "Graph(x=[2680, 302], y=[2680], train_mask=[2680], val_mask=[2680], test_mask=[2680], edge_index=[2, 10296], edge_weight=[10296], edge_attr=[10296])\n",
      "Graph(x=[2780, 302], y=[2680], edge_index=[2, 21096], edge_attr=[21096])\n",
      "Graph(x=[2780, 302], y=[2680], edge_index=[2, 21096], edge_weight=[21096], edge_attr=[21096])\n",
      "Test score after attack for surrogate model: 0.5672.\n",
      "Test score after attack for target model: 0.7065.\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.injection import TDGIA\n",
    "attack = TDGIA(lr=0.01,\n",
    "               n_epoch=1000,\n",
    "               n_inject_max=100,\n",
    "               n_edge_max=200,\n",
    "               feat_lim_min=-1,\n",
    "               feat_lim_max=1,\n",
    "               device=device)\n",
    "graph_attack = attack.attack(model=model_sur,\n",
    "                             graph=graph,\n",
    "                             adj_norm_func=GCNAdjNorm)\n",
    "\n",
    "# apply injection attack\n",
    "test_score_sur = evaluate(model_sur,\n",
    "                          graph_attack,\n",
    "                          mask=test_mask,\n",
    "                          device=device)\n",
    "print(graph_attack)\n",
    "print(\"Test score after attack for surrogate model: {:.4f}.\".format(test_score_sur))\n",
    "\n",
    "# transfer to target model\n",
    "test_score_target_attack = evaluate(model_target,\n",
    "                                    graph_attack,\n",
    "                                    mask=test_mask,\n",
    "                                    device=device)\n",
    "print(\"Test score after attack for target model: {:.4f}.\".format(test_score_target_attack))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bcdc9db1565414677fe31e377cccfec9938e45915a2d99c7e155572c310a6eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
