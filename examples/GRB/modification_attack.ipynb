{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cogdl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/xu-ll18/research/cogdl/examples/GRB/modification_attack.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/examples/GRB/modification_attack.ipynb#ch0000000vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcogdl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrb_data\u001b[39;00m \u001b[39mimport\u001b[39;00m Cora_GRBDataset\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/examples/GRB/modification_attack.ipynb#ch0000000vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcogdl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m set_random_seed\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/examples/GRB/modification_attack.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcogdl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrb_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m evaluate, GCNAdjNorm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cogdl'"
     ]
    }
   ],
   "source": [
    "from cogdl.datasets.grb_data import Cora_GRBDataset\n",
    "from cogdl.utils import set_random_seed\n",
    "from cogdl.utils.grb_utils import evaluate\n",
    "import copy\n",
    "import torch\n",
    "dataset = Cora_GRBDataset()\n",
    "graph = copy.deepcopy(dataset.get(0))\n",
    "# device = \"cpu\"\n",
    "device = \"cuda:0\"\n",
    "device_ids = [0]\n",
    "graph.to(device)\n",
    "test_mask = graph.test_mask\n",
    "set_random_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GCNLayer(\n",
      "      (linear): Linear(in_features=302, out_features=64, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): GCNLayer(\n",
      "      (linear): Linear(in_features=64, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Model Parameters: 19847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 70, train_loss:  2.6498, val_acc:  0.7463:  35%|███▌      | 70/200 [00:01<00:02, 60.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 21-th model to ./checkpoints/model.pt ...\n",
      "Loading model from ./checkpoints/model.pt ...\n",
      "{'test_acc': 0.7885572139303483, 'val_acc': 0.8022388059701493}\n",
      "Test score before attack for surrogate model: 0.7886.\n"
     ]
    }
   ],
   "source": [
    "# train surrogate model\n",
    "from cogdl.models.nn import GCN\n",
    "from cogdl.trainer import Trainer\n",
    "from cogdl.wrappers import fetch_model_wrapper, fetch_data_wrapper\n",
    "model = GCN(\n",
    "    in_feats=graph.num_features,\n",
    "    hidden_size=64,\n",
    "    out_feats=graph.num_classes,\n",
    "    num_layers=2,\n",
    "    dropout=0.5,\n",
    "    activation=None\n",
    ")\n",
    "print(model)\n",
    "mw_class = fetch_model_wrapper(\"node_classification_mw\")\n",
    "dw_class = fetch_data_wrapper(\"node_classification_dw\")\n",
    "optimizer_cfg = dict(\n",
    "                    lr=0.01,\n",
    "                    weight_decay=0\n",
    "                )\n",
    "model_wrapper1 = mw_class(model, optimizer_cfg)\n",
    "dataset_wrapper = dw_class(dataset)\n",
    "trainer = Trainer(epochs=200,\n",
    "                  early_stopping=True,\n",
    "                  patience=50,\n",
    "                  cpu=device==\"cpu\",\n",
    "                  device_ids=[0])\n",
    "trainer.run(model_wrapper1, dataset_wrapper)\n",
    "model.load_state_dict(torch.load(\"./checkpoints/model.pt\"), False)\n",
    "model.to(device)\n",
    "test_score = evaluate(model,\n",
    "                      graph,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"Test score before attack for surrogate model: {:.4f}.\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GCNLayer(\n",
      "      (linear): Linear(in_features=302, out_features=64, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): GCNLayer(\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): GCNLayer(\n",
      "      (linear): Linear(in_features=64, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Model Parameters: 24007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200, train_loss:  0.7375, val_acc:  0.7388: 100%|██████████| 200/200 [00:04<00:00, 46.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 178-th model to ./checkpoints/model.pt ...\n",
      "Loading model from ./checkpoints/model.pt ...\n",
      "{'test_acc': 0.7910447761194029, 'val_acc': 0.7873134328358209}\n",
      "Test score before attack for target model: 0.7910.\n"
     ]
    }
   ],
   "source": [
    "# train target model\n",
    "\n",
    "model_target = GCN(\n",
    "    in_feats=graph.num_features,\n",
    "    hidden_size=64,\n",
    "    out_feats=graph.num_classes,\n",
    "    num_layers=3,\n",
    "    dropout=0.5,\n",
    "    activation=\"relu\"\n",
    ")\n",
    "print(model_target)\n",
    "mw_class = fetch_model_wrapper(\"node_classification_mw\")\n",
    "dw_class = fetch_data_wrapper(\"node_classification_dw\")\n",
    "optimizer_cfg = dict(\n",
    "                    lr=0.01,\n",
    "                    weight_decay=0\n",
    "                )\n",
    "model_wrapper = mw_class(model_target, optimizer_cfg)\n",
    "dataset_wrapper = dw_class(dataset)\n",
    "trainer = Trainer(epochs=200,\n",
    "                  early_stopping=True,\n",
    "                  patience=50,\n",
    "                  cpu=device==\"cpu\",\n",
    "                  device_ids=device_ids)\n",
    "trainer.run(model_wrapper, dataset_wrapper)\n",
    "model_target.load_state_dict(torch.load(\"./checkpoints/model.pt\"), False)\n",
    "model_target.to(device)\n",
    "test_score = evaluate(model_target,\n",
    "                      graph,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"Test score before attack for target model: {:.4f}.\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete internally......\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/xu-ll18/research/cogdl/modification_attack.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=2'>3</a>\u001b[0m ratio_delete \u001b[39m=\u001b[39m \u001b[39m0.6\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=3'>4</a>\u001b[0m attack \u001b[39m=\u001b[39m DICE(\u001b[39mint\u001b[39m(graph\u001b[39m.\u001b[39mto_scipy_csr()[test_mask\u001b[39m.\u001b[39mcpu()]\u001b[39m.\u001b[39mgetnnz() \u001b[39m*\u001b[39m n_mod_ratio),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m               ratio_delete,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m               device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=6'>7</a>\u001b[0m graph_attack \u001b[39m=\u001b[39m attack\u001b[39m.\u001b[39;49mattack(graph)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=7'>8</a>\u001b[0m graph_attack\u001b[39m.\u001b[39mtest_mask \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mtest_mask\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=8'>9</a>\u001b[0m dataset_wrapper\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m graph_attack\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/attack/modification/dice.py:30\u001b[0m, in \u001b[0;36mDICE.attack\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=27'>28</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mindex_target is None.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=28'>29</a>\u001b[0m     exit(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=29'>30</a>\u001b[0m adj_attack \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodification(graph\u001b[39m.\u001b[39;49mto_scipy_csr(), graph\u001b[39m.\u001b[39;49mtest_nid, graph\u001b[39m.\u001b[39;49my)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=30'>31</a>\u001b[0m \u001b[39m# graph = copy.deepcopy(graph)\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=31'>32</a>\u001b[0m \u001b[39m# updateGraph(graph, adj_attack, graph.x)\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=32'>33</a>\u001b[0m \u001b[39m# return graph\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m getGraph(adj_attack, graph\u001b[39m.\u001b[39mx, graph\u001b[39m.\u001b[39my)\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/attack/modification/dice.py:43\u001b[0m, in \u001b[0;36mDICE.modification\u001b[0;34m(self, adj, index_target, labels)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDelete internally......\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=41'>42</a>\u001b[0m n_delete \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mfloor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_edge_mod \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratio_delete))\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=42'>43</a>\u001b[0m index_i, index_j \u001b[39m=\u001b[39m index_target[adj_attack[index_target]\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]], adj_attack[index_target]\u001b[39m.\u001b[39mnonzero()[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=43'>44</a>\u001b[0m target_index_pair \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/attack/modification/dice.py?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m tqdm(\u001b[39mzip\u001b[39m(index_i, index_j), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(index_i)):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/lil.py:213\u001b[0m, in \u001b[0;36mlil_matrix.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/lil.py?line=210'>211</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_intXint(\u001b[39m*\u001b[39mkey)\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/lil.py?line=211'>212</a>\u001b[0m \u001b[39m# Everything else takes the normal path.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/lil.py?line=212'>213</a>\u001b[0m \u001b[39mreturn\u001b[39;00m IndexMixin\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(\u001b[39mself\u001b[39;49m, key)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py:33\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m---> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=32'>33</a>\u001b[0m     row, col \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_indices(key)\n\u001b[1;32m     <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=33'>34</a>\u001b[0m     \u001b[39m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=34'>35</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(row, INT_TYPES):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py:128\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=125'>126</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_indices\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=126'>127</a>\u001b[0m     M, N \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=127'>128</a>\u001b[0m     row, col \u001b[39m=\u001b[39m _unpack_index(key)\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=129'>130</a>\u001b[0m     \u001b[39mif\u001b[39;00m isintlike(row):\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=130'>131</a>\u001b[0m         row \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(row)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py:267\u001b[0m, in \u001b[0;36m_unpack_index\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=264'>265</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid number of indices\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=265'>266</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=266'>267</a>\u001b[0m     idx \u001b[39m=\u001b[39m _compatible_boolean_index(index)\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=267'>268</a>\u001b[0m     \u001b[39mif\u001b[39;00m idx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=268'>269</a>\u001b[0m         row, col \u001b[39m=\u001b[39m index, \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py:360\u001b[0m, in \u001b[0;36m_compatible_boolean_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=357'>358</a>\u001b[0m \u001b[39m# Presence of attribute `ndim` indicates a compatible array type.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=358'>359</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(idx, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m _first_element_bool(idx):\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=359'>360</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _maybe_bool_ndarray(idx)\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=360'>361</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py:333\u001b[0m, in \u001b[0;36m_maybe_bool_ndarray\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=329'>330</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_bool_ndarray\u001b[39m(idx):\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=330'>331</a>\u001b[0m     \u001b[39m\"\"\"Returns a compatible array if elements are boolean.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=331'>332</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=332'>333</a>\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masanyarray(idx)\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=333'>334</a>\u001b[0m     \u001b[39mif\u001b[39;00m idx\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/sparse/_index.py?line=334'>335</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m idx\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/numpy/core/_asarray.py:171\u001b[0m, in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/numpy/core/_asarray.py?line=167'>168</a>\u001b[0m \u001b[39mif\u001b[39;00m like \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/numpy/core/_asarray.py?line=168'>169</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _asanyarray_with_like(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, like\u001b[39m=\u001b[39mlike)\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/numpy/core/_asarray.py?line=170'>171</a>\u001b[0m \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder, subok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py:732\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py?line=729'>730</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py?line=730'>731</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py?line=731'>732</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py?line=732'>733</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py?line=733'>734</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import DICE\n",
    "n_mod_ratio = 0.3\n",
    "ratio_delete = 0.6\n",
    "attack = DICE(int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio),\n",
    "              ratio_delete,\n",
    "              device=device)\n",
    "graph_attack = attack.attack(graph)\n",
    "test_score = evaluate(model, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))\n",
    "test_score = evaluate(model_target, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of target model: {:.4f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 260/2680 [00:37<05:48,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGA attack finished. 260 edges were flipped.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 10296], edge_attr=[10296])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/xu-ll18/research/cogdl/modification_attack.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(graph_attack)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m dataset_wrapper\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m graph_attack\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=6'>7</a>\u001b[0m test_score \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mevaluate(model_wrapper1, dataset_wrapper)[\u001b[39m'\u001b[39m\u001b[39mtest_acc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAfter attack, test score of surrogate model: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(test_score))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xu-ll18/research/cogdl/modification_attack.ipynb#ch0000006vscode-remote?line=8'>9</a>\u001b[0m test_score \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mevaluate(model_wrapper2, dataset_wrapper)[\u001b[39m'\u001b[39m\u001b[39mtest_acc\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/trainer/trainer.py:212\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, model_w, dataset_w, cpu)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=209'>210</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistributed_training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=210'>211</a>\u001b[0m dataset_w\u001b[39m.\u001b[39mprepare_test_data()\n\u001b[0;32m--> <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=211'>212</a>\u001b[0m final_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate(model_w, dataset_w, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevices[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=212'>213</a>\u001b[0m final_test \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(model_w, dataset_w, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevices[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=214'>215</a>\u001b[0m \u001b[39mif\u001b[39;00m final_val \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mval_metric\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m final_val:\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/trainer/trainer.py:407\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[0;34m(self, model_w, dataset_w, device)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=404'>405</a>\u001b[0m val_loader \u001b[39m=\u001b[39m dataset_w\u001b[39m.\u001b[39mon_val_wrapper()\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=405'>406</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=406'>407</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval_step(model_w, val_loader, _device)\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=408'>409</a>\u001b[0m model_w\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=409'>410</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/trainer/trainer.py:503\u001b[0m, in \u001b[0;36mTrainer.val_step\u001b[0;34m(self, model_w, val_loader, device)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=500'>501</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader:\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=501'>502</a>\u001b[0m     batch \u001b[39m=\u001b[39m move_to_device(batch, device)\n\u001b[0;32m--> <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=502'>503</a>\u001b[0m     model_w\u001b[39m.\u001b[39;49mon_val_step(batch)\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=503'>504</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_data_back_to_cpu:\n\u001b[1;32m    <a href='file:///home/xu-ll18/research/cogdl/cogdl/trainer/trainer.py?line=504'>505</a>\u001b[0m         move_to_device(batch, \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/wrappers/model_wrapper/base_model_wrapper.py:76\u001b[0m, in \u001b[0;36mModelWrapper.on_val_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/base_model_wrapper.py?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_val_step\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/base_model_wrapper.py?line=75'>76</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/base_model_wrapper.py?line=76'>77</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_notes(out, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/wrappers/model_wrapper/node_classification/node_classification_mw.py:19\u001b[0m, in \u001b[0;36mNodeClfModelWrapper.val_step\u001b[0;34m(self, subgraph)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/node_classification/node_classification_mw.py?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mval_step\u001b[39m(\u001b[39mself\u001b[39m, subgraph):\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/node_classification/node_classification_mw.py?line=17'>18</a>\u001b[0m     graph \u001b[39m=\u001b[39m subgraph\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/node_classification/node_classification_mw.py?line=18'>19</a>\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(graph)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/node_classification/node_classification_mw.py?line=19'>20</a>\u001b[0m     y \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39my\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/wrappers/model_wrapper/node_classification/node_classification_mw.py?line=20'>21</a>\u001b[0m     val_mask \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mval_mask\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/models/nn/gcn.py:84\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=81'>82</a>\u001b[0m h \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mx\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=82'>83</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=83'>84</a>\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i](graph, h)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/models/nn/gcn.py?line=84'>85</a>\u001b[0m \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/research/cogdl/cogdl/layers/gcn_layer.py:52\u001b[0m, in \u001b[0;36mGCNLayer.forward\u001b[0;34m(self, graph, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, graph, x):\n\u001b[0;32m---> <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=51'>52</a>\u001b[0m     support \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(x)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=52'>53</a>\u001b[0m     out \u001b[39m=\u001b[39m spmm(graph, support)\n\u001b[1;32m     <a href='file:///home/xu-ll18/research/cogdl/cogdl/layers/gcn_layer.py?line=54'>55</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/xu-ll18/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import FGA\n",
    "n_mod_ratio = 0.1\n",
    "attack = FGA(int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio),\n",
    "             device=device)\n",
    "graph_attack = attack.attack(model, graph)\n",
    "test_score = evaluate(model, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))\n",
    "test_score = evaluate(model_target, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2604 [00:00<00:00, 3949.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIP attack finished. 26 edges were flipped.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 10244], edge_attr=[10244])\n",
      "After degree_flip attack, test score: 0.6803\n",
      "After attack, test score of target model: 0.6045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2604 [00:00<00:00, 4217.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIP attack finished. 26 edges were flipped.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 10244], edge_attr=[10244])\n",
      "After eigen_flip attack, test score: 0.6853\n",
      "After attack, test score of target model: 0.6045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import FLIP\n",
    "n_mod_ratio = 0.01\n",
    "n_edge_mod = int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio)\n",
    "attacks = {\n",
    "    \"degree_flip\": FLIP(n_edge_mod, flip_type=\"deg\", mode=\"descend\", device=device),   # degree flipping\n",
    "    \"eigen_flip\": FLIP(n_edge_mod, flip_type=\"eigen\", mode=\"descend\", device=device), # eigen flipping\n",
    "    \"betweenness_flip\": FLIP(n_edge_mod, flip_type=\"bet\", mode=\"ascend\", device=device)     # betweenness flipping\n",
    "}\n",
    "for key, attack in attacks.items():\n",
    "    graph_attack = attack.attack(graph)\n",
    "    print(graph_attack)\n",
    "    test_score = evaluate(model, \n",
    "                          graph_attack,\n",
    "                          mask=test_mask,\n",
    "                          device=device)\n",
    "    print(\"After {} attack, test score of surrogate model: {:.4f}\".format(key, test_score))\n",
    "    test_score = evaluate(model_target, \n",
    "                          graph_attack,\n",
    "                          mask=test_mask,\n",
    "                          device=device)\n",
    "    print(\"After {} attack, test score of target model: {:.4f}\".format(key, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 260/2604 [00:00<00:00, 6407.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAND attack finished. 260 edges were randomly flipped.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 9788], edge_attr=[9788])\n",
      "After attack, test score of surrogate model: 0.5609\n",
      "After attack, test score of target model: 0.5808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import RAND\n",
    "n_mod_ratio = 0.1\n",
    "n_edge_mod = int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio)\n",
    "attack = RAND(n_edge_mod, device=device)\n",
    "graph_attack = attack.attack(graph)\n",
    "print(graph_attack)\n",
    "test_score = evaluate(model, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))\n",
    "test_score = evaluate(model_target, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of target model: {:.4f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 260/2604 [00:00<00:00, 7892.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEA attack finished. 260 edges were flipped.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 9860], edge_attr=[9860])\n",
      "After attack, test score of surrogate model: 0.5510\n",
      "After attack, test score of target model: 0.5970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import NEA\n",
    "n_mod_ratio = 0.1\n",
    "n_edge_mod = int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio)\n",
    "attack = NEA(n_edge_mod, device=device)\n",
    "graph_attack = attack.attack(graph)\n",
    "print(graph_attack)\n",
    "test_score = evaluate(model, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))\n",
    "test_score = evaluate(model_target, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of target model: {:.4f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2604 [00:00<00:00, 7016.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK attack finished. 26 edges were flipped.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 10248], edge_attr=[10248])\n",
      "After attack, test score: 0.6729\n",
      "After attack, test score of target model: 0.5983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import STACK\n",
    "n_mod_ratio = 0.01\n",
    "n_edge_mod = int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio)\n",
    "attack = STACK(n_edge_mod, device=device)\n",
    "graph_attack = attack.attack(graph)\n",
    "print(graph_attack)\n",
    "test_score = evaluate(model, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))\n",
    "test_score = evaluate(model_target, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of target model: {:.4f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/2604 [00:00<00:00, 3242.24it/s]\n",
      "Epoch 499, Loss: 1.8289, Surrogate test score: 0.6194: 100%|██████████| 500/500 [00:07<00:00, 63.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate test score: 0.6194\n",
      "Attack runtime: 7.9239.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 10244], edge_attr=[10244])\n",
      "After attack, test score of surrogate model: 0.4614\n",
      "After attack, test score of target model: 0.4366\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import PGD\n",
    "epsilon = 0.1\n",
    "n_epoch = 500\n",
    "n_mod_ratio = 0.01\n",
    "n_node_mod = int(graph.y.shape[0] * n_mod_ratio)\n",
    "n_edge_mod = int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio)\n",
    "feat_lim_min = 0.0\n",
    "feat_lim_max = 1.0\n",
    "early_stop_patience = 200\n",
    "attack = PGD(epsilon,\n",
    "             n_epoch,\n",
    "             n_node_mod,\n",
    "             n_edge_mod,\n",
    "             feat_lim_min,\n",
    "             feat_lim_max,\n",
    "             early_stop_patience=early_stop_patience,\n",
    "             device=device)\n",
    "graph_attack = attack.attack(model, graph)\n",
    "print(graph_attack)\n",
    "test_score = evaluate(model, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))\n",
    "test_score = evaluate(model_target, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of target model: {:.4f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xu-ll18/research/cogdl/cogdl/attack/modification/prbcd.py:440: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  + (n - row_idx) * ((n - row_idx) - 1) // 2\n",
      "Epoch 499, Loss: 0.0076, Surrogate test score: 0.4366: 100%|██████████| 500/500 [25:30<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate test score: inf\n",
      "Loading search space of epoch -inf\n",
      "\n",
      "Attack runtime: 1541.8050.\n",
      "Graph(x=[2680, 302], y=[2680], edge_index=[2, 10346], edge_attr=[10346])\n",
      "After attack, test score of surrogate model: 0.5075\n",
      "After attack, test score of target model: 0.3221\n"
     ]
    }
   ],
   "source": [
    "from cogdl.attack.modification import PRBCD\n",
    "device=\"cpu\"\n",
    "epsilon = 0.3\n",
    "n_epoch = 500\n",
    "n_mod_ratio = 0.01\n",
    "n_node_mod = int(graph.y.shape[0] * n_mod_ratio)\n",
    "n_edge_mod = int(graph.to_scipy_csr()[test_mask.cpu()].getnnz() * n_mod_ratio)\n",
    "feat_lim_min = 0.0\n",
    "feat_lim_max = 1.0\n",
    "early_stop_patience = 200\n",
    "early_stop_epsilon = 0.001\n",
    "attack = PRBCD(epsilon,\n",
    "              n_epoch,\n",
    "              n_node_mod,\n",
    "              n_edge_mod,\n",
    "              feat_lim_min,\n",
    "              feat_lim_max,\n",
    "              early_stop_patience=early_stop_patience,\n",
    "              early_stop_epsilon=early_stop_epsilon,\n",
    "              device=device)\n",
    "graph_attack = attack.attack(model, graph)\n",
    "print(graph_attack)\n",
    "test_score = evaluate(model, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of surrogate model: {:.4f}\".format(test_score))\n",
    "test_score = evaluate(model_target, \n",
    "                      graph_attack,\n",
    "                      mask=test_mask,\n",
    "                      device=device)\n",
    "print(\"After attack, test score of target model: {:.4f}\".format(test_score))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bcdc9db1565414677fe31e377cccfec9938e45915a2d99c7e155572c310a6eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
