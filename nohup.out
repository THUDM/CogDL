nohup: ignoring input
wandb: Currently logged in as: hwangyeong. Use `wandb login --relogin` to force relogin
wandb: WARNING Path results/wandb_res/wandb/ wasn't writable, using system temp directory.
wandb: WARNING Path results/wandb_res/wandb/ wasn't writable, using system temp directory
wandb: wandb version 0.13.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.1
wandb: Run data is saved locally in /tmp/wandb/run-20220904_043950-2c5r77de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run CogDL_gcc
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hwangyeong/GCC
wandb: üöÄ View run at https://wandb.ai/hwangyeong/GCC/runs/2c5r77de
Namespace(actnn=False, aug='rwr', batch_size=32, beta1=0.9, beta2=0.999, checkpoint_path='./checkpoints/model.pt', clip_grad_norm=1.0, cpu=False, cpu_inference=False, dataset=['gcc_academic gcc_dblp_netrep gcc_dblp_snap gcc_facebook gcc_imdb gcc_livejournal'], degree_embedding_size=16, degree_input=True, devices=[3], distributed=False, do_test=True, do_valid=True, dw='gcc_dw', epochs=100, eval_step=1, finetune=False, fp16=False, freeze=False, freq_embedding_size=16, gnn_model='gin', hidden_size=64, load_emb_path=None, load_model_path='', local_rank=0, log_path='.', logger=None, lr=0.005, master_addr='localhost', master_port=13425, max_degree=512, max_edge_freq=16, max_epoch=None, max_node_freq=16, model=['gcc'], momentum=0.999, mw='gcc_mw', n_trials=3, n_warmup_steps=0.1, nce_k=16384, nce_t=0.07, no_test=True, norm=True, nstage=1, num_copies=6, num_heads=2, num_layers=5, num_samples=2000, num_workers=12, output_size=64, patience=100, positional_embedding_size=32, pretrain=True, progress_bar='epoch', project='cogdl-exp', restart_prob=0.8, resume_training=False, return_model=False, rp_ratio=1, rw_hops=256, save_emb_path=None, save_model_path='saved', seed=[1], split=[0], subgraph_size=128, task='node_classification', unsup=True, use_best_config=False, weight_decay=1e-05)
 
|------------------------------------------------------------------------------------------------------------------------------------|
    *** Running (`gcc_academic gcc_dblp_netrep gcc_dblp_snap gcc_facebook gcc_imdb gcc_livejournal`, `gcc`, `gcc_dw`, `gcc_mw`)
|------------------------------------------------------------------------------------------------------------------------------------|
using queue shape: (16384,64)
Model Parameters: 356256
  0%|          | 0/100 [00:00<?, ?it/s]Epoch: 1, train_loss:  7.1261:   0%|          | 0/100 [03:41<?, ?it/s]Epoch: 1, train_loss:  7.1261:   1%|          | 1/100 [03:41<6:05:07, 221.29s/it]Epoch: 2, train_loss:  5.5234:   1%|          | 1/100 [07:26<6:05:07, 221.29s/it]Epoch: 2, train_loss:  5.5234:   2%|‚ñè         | 2/100 [07:26<6:05:30, 223.78s/it]Epoch: 3, train_loss:  4.8751:   2%|‚ñè         | 2/100 [11:32<6:05:30, 223.78s/it]Epoch: 3, train_loss:  4.8751:   3%|‚ñé         | 3/100 [11:32<6:17:49, 233.71s/it]Epoch: 4, train_loss:  4.4320:   3%|‚ñé         | 3/100 [15:02<6:17:49, 233.71s/it]Epoch: 4, train_loss:  4.4320:   4%|‚ñç         | 4/100 [15:03<5:59:23, 224.62s/it]Epoch: 5, train_loss:  4.1921:   4%|‚ñç         | 4/100 [19:03<5:59:23, 224.62s/it]Epoch: 5, train_loss:  4.1921:   5%|‚ñå         | 5/100 [19:03<6:04:56, 230.49s/it]Epoch: 6, train_loss:  4.0084:   5%|‚ñå         | 5/100 [22:41<6:04:56, 230.49s/it]Epoch: 6, train_loss:  4.0084:   6%|‚ñå         | 6/100 [22:41<5:54:07, 226.04s/it]Epoch: 7, train_loss:  3.8018:   6%|‚ñå         | 6/100 [26:16<5:54:07, 226.04s/it]Epoch: 7, train_loss:  3.8018:   7%|‚ñã         | 7/100 [26:16<5:45:00, 222.59s/it]Epoch: 8, train_loss:  3.6426:   7%|‚ñã         | 7/100 [29:53<5:45:00, 222.59s/it]Epoch: 8, train_loss:  3.6426:   8%|‚ñä         | 8/100 [29:53<5:38:16, 220.62s/it]Epoch: 9, train_loss:  3.4511:   8%|‚ñä         | 8/100 [33:02<5:38:16, 220.62s/it]Epoch: 9, train_loss:  3.4511:   9%|‚ñâ         | 9/100 [33:02<5:19:58, 210.98s/it]Epoch: 10, train_loss:  3.3259:   9%|‚ñâ         | 9/100 [36:45<5:19:58, 210.98s/it]Epoch: 10, train_loss:  3.3259:  10%|‚ñà         | 10/100 [36:45<5:21:44, 214.50s/it]Epoch: 11, train_loss:  3.2121:  10%|‚ñà         | 10/100 [40:47<5:21:44, 214.50s/it]Epoch: 11, train_loss:  3.2121:  11%|‚ñà         | 11/100 [40:47<5:30:45, 222.98s/it]Epoch: 12, train_loss:  3.0760:  11%|‚ñà         | 11/100 [44:10<5:30:45, 222.98s/it]Epoch: 12, train_loss:  3.0760:  12%|‚ñà‚ñè        | 12/100 [44:10<5:18:11, 216.95s/it]Epoch: 13, train_loss:  2.9430:  12%|‚ñà‚ñè        | 12/100 [47:49<5:18:11, 216.95s/it]Epoch: 13, train_loss:  2.9430:  13%|‚ñà‚ñé        | 13/100 [47:49<5:15:23, 217.51s/it]Epoch: 14, train_loss:  2.8705:  13%|‚ñà‚ñé        | 13/100 [51:31<5:15:23, 217.51s/it]Epoch: 14, train_loss:  2.8705:  14%|‚ñà‚ñç        | 14/100 [51:31<5:13:35, 218.79s/it]Epoch: 15, train_loss:  2.7433:  14%|‚ñà‚ñç        | 14/100 [55:19<5:13:35, 218.79s/it]Epoch: 15, train_loss:  2.7433:  15%|‚ñà‚ñå        | 15/100 [55:19<5:14:05, 221.71s/it]Epoch: 16, train_loss:  2.6675:  15%|‚ñà‚ñå        | 15/100 [59:12<5:14:05, 221.71s/it]Epoch: 16, train_loss:  2.6675:  16%|‚ñà‚ñå        | 16/100 [59:12<5:14:58, 224.98s/it]Epoch: 17, train_loss:  2.5777:  16%|‚ñà‚ñå        | 16/100 [1:02:50<5:14:58, 224.98s/it]Epoch: 17, train_loss:  2.5777:  17%|‚ñà‚ñã        | 17/100 [1:02:50<5:08:23, 222.94s/it]Epoch: 18, train_loss:  2.5107:  17%|‚ñà‚ñã        | 17/100 [1:06:11<5:08:23, 222.94s/it]Epoch: 18, train_loss:  2.5107:  18%|‚ñà‚ñä        | 18/100 [1:06:11<4:55:44, 216.40s/it]Epoch: 19, train_loss:  2.4192:  18%|‚ñà‚ñä        | 18/100 [1:09:20<4:55:44, 216.40s/it]Epoch: 19, train_loss:  2.4192:  19%|‚ñà‚ñâ        | 19/100 [1:09:20<4:41:02, 208.18s/it]Epoch: 20, train_loss:  2.3712:  19%|‚ñà‚ñâ        | 19/100 [1:13:09<4:41:02, 208.18s/it]Epoch: 20, train_loss:  2.3712:  20%|‚ñà‚ñà        | 20/100 [1:13:09<4:45:43, 214.29s/it]Epoch: 21, train_loss:  2.3197:  20%|‚ñà‚ñà        | 20/100 [1:17:12<4:45:43, 214.29s/it]Epoch: 21, train_loss:  2.3197:  21%|‚ñà‚ñà        | 21/100 [1:17:12<4:53:31, 222.93s/it]Epoch: 22, train_loss:  2.2502:  21%|‚ñà‚ñà        | 21/100 [1:21:11<4:53:31, 222.93s/it]Epoch: 22, train_loss:  2.2502:  22%|‚ñà‚ñà‚ñè       | 22/100 [1:21:11<4:56:15, 227.89s/it]Epoch: 23, train_loss:  2.2136:  22%|‚ñà‚ñà‚ñè       | 22/100 [1:24:22<4:56:15, 227.89s/it]Epoch: 23, train_loss:  2.2136:  23%|‚ñà‚ñà‚ñé       | 23/100 [1:24:22<4:38:18, 216.87s/it]Epoch: 24, train_loss:  2.1891:  23%|‚ñà‚ñà‚ñé       | 23/100 [1:28:23<4:38:18, 216.87s/it]Epoch: 24, train_loss:  2.1891:  24%|‚ñà‚ñà‚ñç       | 24/100 [1:28:23<4:43:47, 224.05s/it]Epoch: 25, train_loss:  2.1072:  24%|‚ñà‚ñà‚ñç       | 24/100 [1:31:52<4:43:47, 224.05s/it]Epoch: 25, train_loss:  2.1072:  25%|‚ñà‚ñà‚ñå       | 25/100 [1:31:52<4:34:23, 219.51s/it]Epoch: 26, train_loss:  2.1020:  25%|‚ñà‚ñà‚ñå       | 25/100 [1:35:43<4:34:23, 219.51s/it]Epoch: 26, train_loss:  2.1020:  26%|‚ñà‚ñà‚ñå       | 26/100 [1:35:43<4:35:04, 223.04s/it]Epoch: 27, train_loss:  2.0843:  26%|‚ñà‚ñà‚ñå       | 26/100 [1:39:39<4:35:04, 223.04s/it]Epoch: 27, train_loss:  2.0843:  27%|‚ñà‚ñà‚ñã       | 27/100 [1:39:39<4:35:52, 226.75s/it]Epoch: 28, train_loss:  2.0198:  27%|‚ñà‚ñà‚ñã       | 27/100 [1:43:09<4:35:52, 226.75s/it]Epoch: 28, train_loss:  2.0198:  28%|‚ñà‚ñà‚ñä       | 28/100 [1:43:10<4:26:18, 221.92s/it]Epoch: 29, train_loss:  1.9822:  28%|‚ñà‚ñà‚ñä       | 28/100 [1:46:54<4:26:18, 221.92s/it]Epoch: 29, train_loss:  1.9822:  29%|‚ñà‚ñà‚ñâ       | 29/100 [1:46:54<4:23:36, 222.77s/it]Epoch: 30, train_loss:  1.9474:  29%|‚ñà‚ñà‚ñâ       | 29/100 [1:50:21<4:23:36, 222.77s/it]Epoch: 30, train_loss:  1.9474:  30%|‚ñà‚ñà‚ñà       | 30/100 [1:50:21<4:14:09, 217.85s/it]Epoch: 31, train_loss:  1.9202:  30%|‚ñà‚ñà‚ñà       | 30/100 [1:53:54<4:14:09, 217.85s/it]Epoch: 31, train_loss:  1.9202:  31%|‚ñà‚ñà‚ñà       | 31/100 [1:53:54<4:08:58, 216.51s/it]Epoch: 32, train_loss:  1.9214:  31%|‚ñà‚ñà‚ñà       | 31/100 [1:57:34<4:08:58, 216.51s/it]Epoch: 32, train_loss:  1.9214:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [1:57:34<4:06:37, 217.61s/it]Epoch: 33, train_loss:  1.8861:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [2:01:10<4:06:37, 217.61s/it]Epoch: 33, train_loss:  1.8861:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [2:01:11<4:02:34, 217.22s/it]Epoch: 34, train_loss:  1.8623:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [2:04:55<4:02:34, 217.22s/it]Epoch: 34, train_loss:  1.8623:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [2:04:55<4:01:23, 219.45s/it]Epoch: 35, train_loss:  1.8177:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [2:08:36<4:01:23, 219.45s/it]Epoch: 35, train_loss:  1.8177:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [2:08:36<3:58:12, 219.89s/it]Epoch: 36, train_loss:  1.8027:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [2:12:17<3:58:12, 219.89s/it]Epoch: 36, train_loss:  1.8027:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [2:12:17<3:54:56, 220.26s/it]Epoch: 37, train_loss:  1.7925:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [2:16:06<3:54:56, 220.26s/it]Epoch: 37, train_loss:  1.7925:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [2:16:06<3:54:02, 222.90s/it]Epoch: 38, train_loss:  1.7586:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [2:19:48<3:54:02, 222.90s/it]Epoch: 38, train_loss:  1.7586:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [2:19:48<3:49:51, 222.44s/it]Epoch: 39, train_loss:  1.7525:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [2:23:30<3:49:51, 222.44s/it]Epoch: 39, train_loss:  1.7525:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [2:23:30<3:46:13, 222.51s/it]Epoch: 40, train_loss:  1.7347:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [2:26:47<3:46:13, 222.51s/it]Epoch: 40, train_loss:  1.7347:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [2:26:47<3:34:46, 214.78s/it]Epoch: 41, train_loss:  1.7100:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [2:30:36<3:34:46, 214.78s/it]Epoch: 41, train_loss:  1.7100:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [2:30:36<3:35:25, 219.08s/it]Epoch: 42, train_loss:  1.6926:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [2:34:11<3:35:25, 219.08s/it]Epoch: 42, train_loss:  1.6926:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [2:34:11<3:30:33, 217.82s/it]Epoch: 43, train_loss:  1.6732:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [2:37:50<3:30:33, 217.82s/it]Epoch: 43, train_loss:  1.6732:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [2:37:50<3:27:11, 218.09s/it]Epoch: 44, train_loss:  1.6480:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [2:41:17<3:27:11, 218.09s/it]Epoch: 44, train_loss:  1.6480:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [2:41:17<3:20:27, 214.77s/it]Epoch: 45, train_loss:  1.6416:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [2:44:39<3:20:27, 214.77s/it]Epoch: 45, train_loss:  1.6416:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [2:44:40<3:13:36, 211.20s/it]Epoch: 46, train_loss:  1.6013:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [2:48:34<3:13:36, 211.20s/it]Epoch: 46, train_loss:  1.6013:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [2:48:34<3:16:17, 218.10s/it]Epoch: 47, train_loss:  1.6128:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [2:51:52<3:16:17, 218.10s/it]Epoch: 47, train_loss:  1.6128:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [2:51:52<3:07:26, 212.20s/it]Epoch: 48, train_loss:  1.5990:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [2:55:19<3:07:26, 212.20s/it]Epoch: 48, train_loss:  1.5990:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [2:55:19<3:02:36, 210.70s/it]Epoch: 49, train_loss:  1.5658:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [2:58:46<3:02:36, 210.70s/it]Epoch: 49, train_loss:  1.5658:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [2:58:46<2:57:56, 209.35s/it]Epoch: 50, train_loss:  1.5405:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [3:02:16<2:57:56, 209.35s/it]Epoch: 50, train_loss:  1.5405:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [3:02:16<2:54:48, 209.76s/it]Epoch: 51, train_loss:  1.5562:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [3:06:07<2:54:48, 209.76s/it]Epoch: 51, train_loss:  1.5562:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [3:06:07<2:56:28, 216.09s/it]Epoch: 52, train_loss:  1.5280:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [3:09:43<2:56:28, 216.09s/it]Epoch: 52, train_loss:  1.5280:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [3:09:43<2:52:43, 215.91s/it]Epoch: 53, train_loss:  1.5561:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [3:13:24<2:52:43, 215.91s/it]Epoch: 53, train_loss:  1.5561:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [3:13:24<2:50:17, 217.39s/it]Epoch: 54, train_loss:  1.5134:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [3:16:45<2:50:17, 217.39s/it]Epoch: 54, train_loss:  1.5134:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [3:16:45<2:42:56, 212.54s/it]Epoch: 55, train_loss:  1.4882:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [3:20:21<2:42:56, 212.54s/it]Epoch: 55, train_loss:  1.4882:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [3:20:21<2:40:09, 213.54s/it]Epoch: 56, train_loss:  1.4722:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [3:24:00<2:40:09, 213.54s/it]Epoch: 56, train_loss:  1.4722:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [3:24:00<2:37:53, 215.30s/it]Epoch: 57, train_loss:  1.4800:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [3:27:53<2:37:53, 215.30s/it]Epoch: 57, train_loss:  1.4800:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [3:27:53<2:38:07, 220.65s/it]Epoch: 58, train_loss:  1.4621:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [3:31:23<2:38:07, 220.65s/it]Epoch: 58, train_loss:  1.4621:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [3:31:23<2:32:05, 217.28s/it]Epoch: 59, train_loss:  1.4584:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [3:35:08<2:32:05, 217.28s/it]Epoch: 59, train_loss:  1.4584:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [3:35:08<2:30:02, 219.58s/it]Epoch: 60, train_loss:  1.4439:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [3:38:37<2:30:02, 219.58s/it]Epoch: 60, train_loss:  1.4439:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [3:38:37<2:24:18, 216.47s/it]Epoch: 61, train_loss:  1.4521:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [3:41:56<2:24:18, 216.47s/it]Epoch: 61, train_loss:  1.4521:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [3:41:56<2:17:15, 211.17s/it]Epoch: 62, train_loss:  1.4238:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [3:45:20<2:17:15, 211.17s/it]Epoch: 62, train_loss:  1.4238:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [3:45:20<2:12:28, 209.18s/it]Epoch: 63, train_loss:  1.3990:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [3:49:00<2:12:28, 209.18s/it]Epoch: 63, train_loss:  1.3990:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [3:49:00<2:11:02, 212.51s/it]Epoch: 64, train_loss:  1.4066:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [3:52:35<2:11:02, 212.51s/it]Epoch: 64, train_loss:  1.4066:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [3:52:35<2:07:56, 213.22s/it]Epoch: 65, train_loss:  1.3905:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [3:56:12<2:07:56, 213.22s/it]Epoch: 65, train_loss:  1.3905:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [3:56:12<2:04:56, 214.20s/it]Epoch: 66, train_loss:  1.3827:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [3:59:51<2:04:56, 214.20s/it]Epoch: 66, train_loss:  1.3827:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [3:59:51<2:02:15, 215.74s/it]Epoch: 67, train_loss:  1.3603:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [4:03:11<2:02:15, 215.74s/it]Epoch: 67, train_loss:  1.3603:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [4:03:11<1:56:07, 211.12s/it]Epoch: 68, train_loss:  1.3613:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [4:06:51<1:56:07, 211.12s/it]Epoch: 68, train_loss:  1.3613:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [4:06:51<1:53:56, 213.63s/it]Epoch: 69, train_loss:  1.3568:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [4:10:22<1:53:56, 213.63s/it]Epoch: 69, train_loss:  1.3568:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [4:10:22<1:50:02, 212.99s/it]Epoch: 70, train_loss:  1.3579:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [4:14:14<1:50:02, 212.99s/it]Epoch: 70, train_loss:  1.3579:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [4:14:14<1:49:13, 218.46s/it]Epoch: 71, train_loss:  1.3471:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [4:17:45<1:49:13, 218.46s/it]Epoch: 71, train_loss:  1.3471:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [4:17:45<1:44:37, 216.47s/it]Epoch: 72, train_loss:  1.3371:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [4:20:58<1:44:37, 216.47s/it]Epoch: 72, train_loss:  1.3371:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [4:20:58<1:37:37, 209.18s/it]Epoch: 73, train_loss:  1.3131:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [4:24:35<1:37:37, 209.18s/it]Epoch: 73, train_loss:  1.3131:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [4:24:35<1:35:13, 211.63s/it]Epoch: 74, train_loss:  1.2986:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [4:27:54<1:35:13, 211.63s/it]Epoch: 74, train_loss:  1.2986:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [4:27:54<1:30:01, 207.74s/it]Epoch: 75, train_loss:  1.2936:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [4:31:46<1:30:01, 207.74s/it]Epoch: 75, train_loss:  1.2936:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [4:31:46<1:29:35, 215.03s/it]Epoch: 76, train_loss:  1.3004:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [4:35:43<1:29:35, 215.03s/it]Epoch: 76, train_loss:  1.3004:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [4:35:43<1:28:43, 221.81s/it]Epoch: 77, train_loss:  1.2973:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [4:39:26<1:28:43, 221.81s/it]Epoch: 77, train_loss:  1.2973:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [4:39:26<1:25:09, 222.14s/it]Epoch: 78, train_loss:  1.2687:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [4:42:51<1:25:09, 222.14s/it]Epoch: 78, train_loss:  1.2687:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [4:42:51<1:19:33, 216.98s/it]Epoch: 79, train_loss:  1.2801:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [4:46:23<1:19:33, 216.98s/it]Epoch: 79, train_loss:  1.2801:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [4:46:23<1:15:24, 215.43s/it]Epoch: 80, train_loss:  1.2584:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [4:49:58<1:15:24, 215.43s/it]Epoch: 80, train_loss:  1.2584:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [4:49:58<1:11:47, 215.40s/it]Epoch: 81, train_loss:  1.2550:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [4:53:26<1:11:47, 215.40s/it]Epoch: 81, train_loss:  1.2550:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [4:53:26<1:07:26, 212.96s/it]Epoch: 82, train_loss:  1.2521:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [4:56:58<1:07:26, 212.96s/it]Epoch: 82, train_loss:  1.2521:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [4:56:58<1:03:51, 212.88s/it]Epoch: 83, train_loss:  1.2470:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [5:00:23<1:03:51, 212.88s/it]Epoch: 83, train_loss:  1.2470:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [5:00:23<59:35, 210.34s/it]  Epoch: 84, train_loss:  1.2442:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [5:03:55<59:35, 210.34s/it]Epoch: 84, train_loss:  1.2442:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [5:03:55<56:12, 210.79s/it]Epoch: 85, train_loss:  1.2304:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [5:07:40<56:12, 210.79s/it]Epoch: 85, train_loss:  1.2304:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [5:07:40<53:46, 215.09s/it]Epoch: 86, train_loss:  1.2254:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [5:11:40<53:46, 215.09s/it]Epoch: 86, train_loss:  1.2254:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [5:11:40<51:57, 222.69s/it]Epoch: 87, train_loss:  1.2243:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [5:15:05<51:57, 222.69s/it]Epoch: 87, train_loss:  1.2243:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [5:15:05<47:04, 217.27s/it]Epoch: 88, train_loss:  1.2170:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [5:18:52<47:04, 217.27s/it]Epoch: 88, train_loss:  1.2170:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [5:18:52<44:03, 220.29s/it]Epoch: 89, train_loss:  1.1855:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [5:22:25<44:03, 220.29s/it]Epoch: 89, train_loss:  1.1855:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [5:22:25<39:59, 218.15s/it]Epoch: 90, train_loss:  1.2067:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [5:26:16<39:59, 218.15s/it]Epoch: 90, train_loss:  1.2067:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [5:26:16<37:00, 222.07s/it]Epoch: 91, train_loss:  1.1868:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [5:29:42<37:00, 222.07s/it]Epoch: 91, train_loss:  1.1868:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [5:29:42<32:34, 217.19s/it]Epoch: 92, train_loss:  1.1868:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [5:33:17<32:34, 217.19s/it]Epoch: 92, train_loss:  1.1868:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [5:33:17<28:51, 216.45s/it]Epoch: 93, train_loss:  1.1836:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [5:36:47<28:51, 216.45s/it]Epoch: 93, train_loss:  1.1836:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [5:36:47<25:02, 214.63s/it]wandb: Network error (ReadTimeout), entering retry loop.
Epoch: 94, train_loss:  1.2005:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [5:40:15<25:02, 214.63s/it]Epoch: 94, train_loss:  1.2005:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [5:40:15<21:15, 212.55s/it]Epoch: 95, train_loss:  1.1724:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [5:43:46<21:15, 212.55s/it]Epoch: 95, train_loss:  1.1724:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [5:43:46<17:39, 211.98s/it]Epoch: 96, train_loss:  1.1653:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [5:47:25<17:39, 211.98s/it]Epoch: 96, train_loss:  1.1653:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [5:47:25<14:16, 214.12s/it]Epoch: 97, train_loss:  1.1694:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [5:50:41<14:16, 214.12s/it]Epoch: 97, train_loss:  1.1694:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [5:50:41<10:26, 208.68s/it]Epoch: 98, train_loss:  1.1640:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [5:54:31<10:26, 208.68s/it]Epoch: 98, train_loss:  1.1640:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [5:54:31<07:10, 215.12s/it]Epoch: 99, train_loss:  1.1444:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [5:58:07<07:10, 215.12s/it]Epoch: 99, train_loss:  1.1444:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [5:58:08<03:35, 215.56s/it]Epoch: 100, train_loss:  1.1638:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [6:01:36<03:35, 215.56s/it]Epoch: 100, train_loss:  1.1638: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [6:01:36<00:00, 213.48s/it]Epoch: 100, train_loss:  1.1638: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [6:01:36<00:00, 216.97s/it]
Saving 0-th model to ./checkpoints/model.pt ...
Loading model from ./checkpoints/model.pt ...
None
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb: loss ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:   lr ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb: loss 1.23436
wandb:   lr 0.0
wandb: 
wandb: Synced CogDL_gcc: https://wandb.ai/hwangyeong/GCC/runs/2c5r77de
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /tmp/wandb/run-20220904_043950-2c5r77de/logs
Traceback (most recent call last):
  File "try.py", line 31, in <module>
    unsup=True, #must
  File "/home/huanjing/work_document/NE/cogdl_gcc_revision/cogdl/experiments.py", line 378, in experiment
    return raw_experiment(args)
  File "/home/huanjing/work_document/NE/cogdl_gcc_revision/cogdl/experiments.py", line 305, in raw_experiment
    output_results(results_dict, tablefmt)
  File "/home/huanjing/work_document/NE/cogdl_gcc_revision/cogdl/experiments.py", line 255, in output_results
    col_names = ["Variant"] + list(results_dict[variant][-1].keys())
AttributeError: 'NoneType' object has no attribute 'keys'
